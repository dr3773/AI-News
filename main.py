import os
import logging
import html
import re
from time import mktime
from datetime import datetime, time as dtime
from zoneinfo import ZoneInfo
from typing import List, Dict, Set
from urllib.parse import urlparse

import feedparser
from telegram import Update
from telegram.constants import ParseMode
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
    Defaults,
)

# ----------------- –õ–û–ì–ò -----------------
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger("ai_news_bot")

# ----------------- –ù–ê–°–¢–†–û–ô–ö–ò -----------------

TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID_ENV = os.getenv("CHANNEL_ID")
ADMIN_ID_ENV = os.getenv("ADMIN_ID")

if not TOKEN:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
if not CHANNEL_ID_ENV:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω CHANNEL_ID –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

CHANNEL_ID = int(CHANNEL_ID_ENV)
ADMIN_ID = int(ADMIN_ID_ENV) if ADMIN_ID_ENV else None

TZ = ZoneInfo("Asia/Dushanbe")

# --- RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–∏ ---

# Google News –ø–æ –ò–ò –Ω–∞ —Ä—É—Å—Å–∫–æ–º (—Ç—è–Ω–µ—Ç –º–Ω–æ–≥–æ –†–§-–°–ú–ò —Å—Ä–∞–∑—É)
GOOGLE_NEWS_RU_AI = (
    "https://news.google.com/rss/search?"
    "q=–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç+OR+–Ω–µ–π—Ä–æ—Å–µ—Ç–∏+OR+AI&"
    "hl=ru&gl=RU&ceid=RU:ru"
)

# –†–§-–∏—Å—Ç–æ—á–Ω–∏–∫–∏ —á–µ—Ä–µ–∑ Google News (—Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–æ–º–µ–Ω—É)
RUS_SOURCES = [
    "https://news.google.com/rss/search?q=site:ria.ru+–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
    "https://news.google.com/rss/search?q=site:tass.ru+–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
    "https://news.google.com/rss/search?q=site:kommersant.ru+–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
    "https://news.google.com/rss/search?q=site:vedomosti.ru+–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
    "https://news.google.com/rss/search?q=site:rbc.ru+–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
    "https://news.google.com/rss/search?q=site:lenta.ru+–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
    "https://news.google.com/rss/search?q=site:habr.com+–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
]

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ AI/tech-–∏—Å—Ç–æ—á–Ω–∏–∫–∏
GLOBAL_SOURCES = [
    "https://www.marktechpost.com/feed",                 # MarkTechPost
    "https://venturebeat.com/category/ai/feed/",         # VentureBeat AI
    "https://syncedreview.com/feed",                     # Synced
    "https://unite.ai/feed/",                            # Unite.AI
    "https://the-decoder.com/feed/",                     # THE DECODER
    "https://techcrunch.com/feed/",                      # TechCrunch
    "https://www.theverge.com/rss/index.xml",            # The Verge
    "https://feeds.arstechnica.com/arstechnica/index",   # Ars Technica
]

FEED_URLS: List[str] = [GOOGLE_NEWS_RU_AI] + RUS_SOURCES + GLOBAL_SOURCES

# —Ñ–∞–π–ª, –≥–¥–µ —Ö—Ä–∞–Ω–∏–º —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –¥—É–±–ª–µ–π
SENT_URLS_FILE = "sent_urls.txt"
SENT_URLS: Set[str] = set()

# –±—É—Ñ–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è –¥–ª—è –≤–µ—á–µ—Ä–Ω–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞
TODAY_NEWS: List[Dict[str, str]] = []

NEWS_INTERVAL_SECONDS = 45 * 60  # –∫–∞–∂–¥—ã–µ 45 –º–∏–Ω—É—Ç

_html_tag_re = re.compile(r"<[^>]+>")


# ----------------- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò -----------------

def load_sent_urls() -> None:
    """–ó–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞."""
    global SENT_URLS
    if not os.path.exists(SENT_URLS_FILE):
        SENT_URLS = set()
        return
    try:
        with open(SENT_URLS_FILE, "r", encoding="utf-8") as f:
            SENT_URLS = {line.strip() for line in f if line.strip()}
    except Exception as e:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å SENT_URLS: %s", e)
        SENT_URLS = set()


def save_sent_urls() -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –≤ —Ñ–∞–π–ª."""
    try:
        with open(SENT_URLS_FILE, "w", encoding="utf-8") as f:
            for url in sorted(SENT_URLS):
                f.write(url + "\n")
    except Exception as e:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å SENT_URLS: %s", e)


def clean_html(text: str | None) -> str:
    """–£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏, &nbsp; –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
    if not text:
        return ""
    text = html.unescape(text)
    text = _html_tag_re.sub(" ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()


def extract_image(entry) -> str | None:
    """–ü—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ RSS (media_content, media_thumbnail, enclosure)."""
    # media_content
    media = getattr(entry, "media_content", None)
    if media and isinstance(media, list):
        url = media[0].get("url")
        if url:
            return url

    # media_thumbnail
    thumb = getattr(entry, "media_thumbnail", None)
    if thumb and isinstance(thumb, list):
        url = thumb[0].get("url")
        if url:
            return url

    # enclosure / links
    links = getattr(entry, "links", [])
    for l in links:
        if "image" in l.get("type", "") and l.get("href"):
            return l["href"]

    return None


def get_source_name(entry, fallback_link: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: —Å–Ω–∞—á–∞–ª–∞ entry.source.title, –ø–æ—Ç–æ–º –¥–æ–º–µ–Ω."""
    source = getattr(entry, "source", None)
    if source and getattr(source, "title", None):
        s = str(source.title).strip()
        if s:
            return s

    # –ü–∞—Ä—Å–∏–º –¥–æ–º–µ–Ω –∏–∑ —Å—Å—ã–ª–∫–∏
    try:
        netloc = urlparse(fallback_link).netloc
        if netloc.startswith("www."):
            netloc = netloc[4:]
        return netloc or "–ò—Å—Ç–æ—á–Ω–∏–∫"
    except Exception:
        return "–ò—Å—Ç–æ—á–Ω–∏–∫"


def collect_new_articles(limit: int = 5) -> List[Dict]:
    """
    –û–±—Ö–æ–¥–∏—Ç –≤—Å–µ RSS-–ª–µ–Ω—Ç—ã, —Å–æ–±–∏—Ä–∞–µ—Ç –¥–æ limit –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π,
    –∫–æ—Ç–æ—Ä—ã—Ö –µ—â—ë –Ω–µ—Ç –≤ SENT_URLS.
    """
    items: List[Dict] = []

    for feed_url in FEED_URLS:
        try:
            parsed = feedparser.parse(feed_url)
        except Exception as e:
            logger.warning("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS %s: %s", feed_url, e)
            continue

        for entry in getattr(parsed, "entries", []):
            link = entry.get("link")
            if not link:
                continue
            if link in SENT_URLS:
                continue

            title = clean_html(entry.get("title"))
            summary = clean_html(
                entry.get("summary") or entry.get("description") or ""
            )

            if not title and not summary:
                continue

            published_parsed = entry.get("published_parsed") or entry.get("updated_parsed")
            ts = mktime(published_parsed) if published_parsed else 0

            items.append(
                {
                    "title": title,
                    "summary": summary,
                    "url": link,
                    "source": get_source_name(entry, link),
                    "image": extract_image(entry),
                    "ts": ts,
                }
            )

    if not items:
        return []

    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
    items.sort(key=lambda x: x["ts"], reverse=True)

    new_items: List[Dict] = []
    for it in items:
        if len(new_items) >= limit:
            break
        url = it["url"]
        if url in SENT_URLS:
            continue
        SENT_URLS.add(url)
        new_items.append(it)

    save_sent_urls()
    return new_items


def build_body_text(title: str, summary: str) -> str:
    """
    –î–µ–ª–∞–µ–º –±–æ–ª–µ–µ-–º–µ–Ω–µ–µ "—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π" —Ç–µ–∫—Å—Ç –ø–æ-—Ä—É—Å—Å–∫–∏ –±–µ–∑ OpenAI.
    ‚Ä¢ –µ—Å–ª–∏ summary –µ—Å—Ç—å –∏ –æ–Ω –Ω–µ –∫–æ–ø–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ ‚Äì –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ;
    ‚Ä¢ –µ—Å–ª–∏ summary –∫–æ—Ä–æ—Ç–∫–∏–π ‚Äì –¥–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
    """
    t = (title or "").strip()
    s = (summary or "").strip()
    tl = t.lower()
    sl = s.lower()

    if s and sl != tl:
        base = s
    else:
        base = t

    if len(base) < 160:
        body = (
            f"{base} –≠—Ç–æ –æ–¥–Ω–∞ –∏–∑ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Å—Ñ–µ—Ä–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞. "
            f"–¢–∞–∫–∏–µ —Å–æ–±—ã—Ç–∏—è –ø–æ–º–æ–≥–∞—é—Ç –ø–æ–Ω–∏–º–∞—Ç—å, –∫–∞–∫ —Ä–∞–∑–≤–∏–≤–∞–µ—Ç—Å—è –ò–ò –∏ –∫–∞–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ "
            f"—Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –∫–ª—é—á–µ–≤—ã–º–∏ –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–π –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤."
        )
    else:
        body = base

    return body


def build_post_text(item: Dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç –ø–æ—Å—Ç–∞:
    üß† <b>–ó–∞–≥–æ–ª–æ–≤–æ–∫</b>

    —Ç–µ–∫—Å—Ç

    ‚ûú –ò—Å—Ç–æ—á–Ω–∏–∫ (—Å–ª–æ–≤–æ ¬´–ò—Å—Ç–æ—á–Ω–∏–∫¬ª ‚Äî –∫–ª–∏–∫–∞–±–µ–ª—å–Ω–∞—è —Å—Å—ã–ª–∫–∞, —É—Ä–ª –Ω–µ –≤–∏–¥–µ–Ω)
    """
    title = item["title"]
    summary = item["summary"]
    url = item["url"]

    body = build_body_text(title, summary)

    safe_title = html.escape(title)
    safe_body = html.escape(body)
    safe_url = html.escape(url, quote=True)

    if len(safe_body) > 3500:
        safe_body = safe_body[:3490] + "‚Ä¶"

    parts = [
        f"üß† <b>{safe_title}</b>",
        "",
        safe_body,
        "",
        f'<a href="{safe_url}">‚ûú –ò—Å—Ç–æ—á–Ω–∏–∫</a>',
    ]
    return "\n".join(parts)


async def notify_admin(context: ContextTypes.DEFAULT_TYPE, text: str) -> None:
    if not ADMIN_ID:
        return
    try:
        await context.bot.send_message(chat_id=ADMIN_ID, text=f"‚ö†Ô∏è AI News: {text}")
    except Exception:
        logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É")


async def post_single_news(context: ContextTypes.DEFAULT_TYPE, item: Dict) -> None:
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –û–î–ù–û–ô –Ω–æ–≤–æ—Å—Ç–∏ –≤ –∫–∞–Ω–∞–ª (—Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π, –µ—Å–ª–∏ –µ—Å—Ç—å)."""
    text = build_post_text(item)

    # –¥–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä –¥–ª—è –≤–µ—á–µ—Ä–Ω–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞
    today_str = datetime.now(TZ).date().isoformat()
    TODAY_NEWS.append(
        {
            "title": item["title"],
            "url": item["url"],
            "date": today_str,
        }
    )

    try:
        if item.get("image"):
            await context.bot.send_photo(
                chat_id=CHANNEL_ID,
                photo=item["image"],
                caption=text,
                parse_mode=ParseMode.HTML,
            )
        else:
            await context.bot.send_message(
                chat_id=CHANNEL_ID,
                text=text,
                parse_mode=ParseMode.HTML,
                disable_web_page_preview=False,
            )
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: %s", e)
        await notify_admin(context, f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: {e}")


# ----------------- JOB'–´ -----------------

async def periodic_news_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–∞–∂–¥—ã–µ NEWS_INTERVAL_SECONDS –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
    –∏ –ø—É–±–ª–∏–∫—É–µ–º –¥–æ 3 —à—Ç—É–∫.
    """
    try:
        logger.info("–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –æ–±—Ö–æ–¥ RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤‚Ä¶")
        items = collect_new_articles(limit=3)
        if not items:
            logger.info("–ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            return

        for it in items:
            await post_single_news(context, it)

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ periodic_news_job: %s", e)
        await notify_admin(context, f"–û—à–∏–±–∫–∞ –≤ periodic_news_job: {e}")


async def daily_digest_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00 –ø–æ –î—É—à–∞–Ω–±–µ:
    —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ –Ω–∞ –≥–ª–∞–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –¥–µ–Ω—å.
    """
    try:
        today_str = datetime.now(TZ).date().isoformat()
        today_items = [n for n in TODAY_NEWS if n["date"] == today_str]

        if not today_items:
            logger.info("–ó–∞ —Å–µ–≥–æ–¥–Ω—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç ‚Äî –¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º.")
            return

        lines = ["üåô <b>–í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –ò–ò</b>", ""]
        for i, it in enumerate(today_items, start=1):
            safe_title = html.escape(it["title"])
            safe_url = html.escape(it["url"], quote=True)
            lines.append(f'{i}. <a href="{safe_url}">{safe_title}</a>')

        text = "\n".join(lines)

        await context.bot.send_message(
            chat_id=CHANNEL_ID,
            text=text,
            parse_mode=ParseMode.HTML,
            disable_web_page_preview=True,
        )

        TODAY_NEWS.clear()
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ daily_digest_job: %s", e)
        await notify_admin(context, f"–û—à–∏–±–∫–∞ –≤ daily_digest_job: {e}")


# ----------------- –•–≠–ù–î–õ–ï–†–´ -----------------

async def start_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç–≤–µ—Ç –Ω–∞ /start –≤ –ª–∏—á–∫–µ —Å –±–æ—Ç–æ–º."""
    if update.effective_chat is None:
        return

    await update.effective_chat.send_message(
        "üëã –ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –æ–± –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ.\n\n"
        "‚Ä¢ –í —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è —è –ø—É–±–ª–∏–∫—É—é —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –ò–ò –∏–∑ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∏ –º–∏—Ä–æ–≤—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.\n"
        "‚Ä¢ –í 21:00 –ø–æ –î—É—à–∞–Ω–±–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ –¥–µ–Ω—å."
    )


# ----------------- MAIN -----------------

def main() -> None:
    logger.info("–ó–∞–ø—É—Å–∫ AI News –±–æ—Ç–∞")

    load_sent_urls()

    defaults = Defaults(
        parse_mode=ParseMode.HTML,
        disable_web_page_preview=False,
    )

    app = (
        Application.builder()
        .token(TOKEN)
        .defaults(defaults)
        .build()
    )

    # –∫–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", start_handler))

    # –∑–∞–¥–∞—á–∏ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
    job_queue = app.job_queue
    if job_queue is None:
        raise RuntimeError(
            "JobQueue –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ –≤ requirements.txt: "
            "python-telegram-bot[job-queue]==21.6"
        )

    # –∫–∞–∂–¥—ã–µ 45 –º–∏–Ω—É—Ç ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
    job_queue.run_repeating(
        periodic_news_job,
        interval=NEWS_INTERVAL_SECONDS,
        first=30,
        name="periodic_news",
    )

    # –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00 –ø–æ –î—É—à–∞–Ω–±–µ
    job_queue.run_daily(
        daily_digest_job,
        time=dtime(21, 0, tzinfo=TZ),
        name="daily_digest",
    )

    # –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞ (polling)
    app.run_polling(allowed_updates=["message"])


if __name__ == "__main__":
    main()
