import os
import logging
import re
from datetime import time, date
from zoneinfo import ZoneInfo
from typing import List, Dict, Optional
from html import unescape, escape as html_escape
import urllib.request
import xml.etree.ElementTree as ET

from telegram.ext import Application, ContextTypes

# ============ –õ–û–ì–ò ============
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)

# ============ –ü–ï–†–ï–ú–ï–ù–ù–´–ï –û–ö–†–£–ñ–ï–ù–ò–Ø ============
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID_ENV = os.getenv("CHANNEL_ID")
ADMIN_ID_ENV = os.getenv("ADMIN_ID")  # —Ç–≤–æ–π Telegram ID (–æ–ø—Ü–∏–æ–Ω–∞–ª–µ–Ω)

if not TOKEN:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
if not CHANNEL_ID_ENV:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω CHANNEL_ID –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

CHANNEL_ID = int(CHANNEL_ID_ENV)
ADMIN_ID: Optional[int] = int(ADMIN_ID_ENV) if ADMIN_ID_ENV else None

# –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–æ–Ω–∞ –î—É—à–∞–Ω–±–µ
TZ = ZoneInfo("Asia/Dushanbe")

# ============ –ò–°–¢–û–ß–ù–ò–ö–ò –ò–ò-–ù–û–í–û–°–¢–ï–ô ============
RSS_FEEDS: List[str] = [
    # –ú–∏—Ä –ò–ò ‚Äî –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ —Ö–µ–¥–ª–∞–π–Ω—ã
    (
        "https://news.google.com/rss/search?q="
        "artificial+intelligence+OR+AI+model+OR+machine+learning"
        "+-crypto+-casino&hl=en-US&gl=US&ceid=US:en"
    ),
    # –ú–∏—Ä –ò–ò ‚Äî —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ —Ö–µ–¥–ª–∞–π–Ω—ã
    (
        "https://news.google.com/rss/search?q="
        "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç+OR+–ò–ò+–Ω–µ–π—Ä–æ—Å–µ—Ç–∏"
        "+-–∫–∞–∑–∏–Ω–æ+-–±—É–∫–º–µ–∫–µ—Ä&hl=ru&gl=RU&ceid=RU:ru"
    ),
    # –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ò–ò, LLM –∏ ChatGPT
    (
        "https://news.google.com/rss/search?q="
        "ChatGPT+OR+\"large+language+model\"+OR+\"–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π+–ò–ò\""
        "&hl=ru&gl=RU&ceid=RU:ru"
    ),
    # –ë–∏–∑–Ω–µ—Å –∏ —Å—Ç–∞—Ä—Ç–∞–ø—ã –≤ –ò–ò
    (
        "https://news.google.com/rss/search?q="
        "\"AI startup\"+OR+\"AI company\"+OR+\"–ò–ò\"+—Å—Ç–∞—Ä—Ç–∞–ø"
        "&hl=en-US&gl=US&ceid=US:en"
    ),
]

# namespace –¥–ª—è media:thumbnail / media:content
NS = {"media": "http://search.yahoo.com/mrss/"}

# ============ –ü–ê–ú–Ø–¢–¨ –ù–ê –î–ï–ù–¨ ============
CURRENT_DAY: date = date.today()
POSTED_URLS: set[str] = set()  # —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å
DAILY_ITEMS: List[Dict] = []   # –¥–ª—è –≤–µ—á–µ—Ä–Ω–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞


def reset_day_if_needed() -> None:
    """–°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è, –µ—Å–ª–∏ –Ω–∞—Å—Ç—É–ø–∏–ª –Ω–æ–≤—ã–π –¥–µ–Ω—å."""
    global CURRENT_DAY, POSTED_URLS, DAILY_ITEMS
    today = date.today()
    if today != CURRENT_DAY:
        logger.info("–ù–æ–≤—ã–π –¥–µ–Ω—å ‚Äî –æ—á–∏—â–∞—é –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –ø–∞–º—è—Ç—å –Ω–æ–≤–æ—Å—Ç–µ–π")
        CURRENT_DAY = today
        POSTED_URLS = set()
        DAILY_ITEMS = []


# ============ –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –¢–ï–ö–°–¢–ê ============

def clean_html(text: str) -> str:
    """–£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
    text = re.sub(r"<[^>]+>", " ", text)
    text = unescape(text)
    text = re.sub(r"\s+", " ", text).strip()
    return text


def shorten_summary(text: str, max_len: int = 350) -> str:
    """
    –û–±—Ä–µ–∑–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ —Ä–∞–∑—É–º–Ω–æ–π –¥–ª–∏–Ω—ã (1‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
    """
    if len(text) <= max_len:
        return text

    cut = text[:max_len]
    last_dot = cut.rfind(".")
    if last_dot > max_len * 0.5:
        cut = cut[: last_dot + 1]
    return cut.strip() + "‚Ä¶"


# ============ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –î–õ–Ø –¢–ï–ì–û–í ============

def classify_category(title: str, summary: Optional[str]) -> str:
    """
    –ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º,
    —Ç–æ–ª—å–∫–æ –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ç–µ–≥–∞ (–±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤).
    """
    text = f"{title} {summary or ''}".lower()

    if any(w in text for w in ["–º–æ–¥–µ–ª—å", "–Ω–µ–π—Ä–æ—Å–µ—Ç—å", "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏", "transformer", "llm", "architecture"]):
        return "–º–æ–¥–µ–ª–∏ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –ò–ò"

    if any(w in text for w in ["—Å—Ç–∞—Ä—Ç–∞–ø", "startup", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏", "funding", "–æ—Ü–µ–Ω–∫–∞", "—Ä–∞—É–Ω–¥", "venture"]):
        return "—Å—Ç–∞—Ä—Ç–∞–ø—ã –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ –ò–ò"

    if any(w in text for w in ["–º–∏–Ω–∏—Å—Ç–µ—Ä", "—Ä–µ–≥—É–ª—è—Ü", "regulation", "policy", "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç", "safety", "governance"]):
        return "—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –ò–ò"

    if any(w in text for w in ["–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "—Å–µ—Ä–≤–∏—Å", "product", "assistant", "–≤–Ω–µ–¥—Ä–∏–ª–∏", "–∑–∞–ø—É—Å—Ç–∏–ª–∏"]):
        return "–ø—Ä–∏–∫–ª–∞–¥–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –∏ —Å–µ—Ä–≤–∏—Å—ã –Ω–∞ –±–∞–∑–µ –ò–ò"

    if any(w in text for w in ["–º–µ–¥–∏—Ü–∏–Ω–∞", "health", "diagnosis", "–∫–ª–∏–Ω–∏–∫", "–ø–∞—Ü–∏–µ–Ω—Ç"]):
        return "–ò–ò –≤ –º–µ–¥–∏—Ü–∏–Ω–µ"

    if any(w in text for w in ["–æ–±—Ä–∞–∑–æ–≤–∞–Ω", "education", "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç", "–∫—É—Ä—Å", "–æ–±—É—á–µ–Ω–∏"]):
        return "–ò–ò –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏"

    return "–æ–±—â–∏–µ —Ç—Ä–µ–Ω–¥—ã –∏ —Ä–∞–∑–≤–∏—Ç–∏–µ –ò–ò"


def category_tag(title: str, summary: Optional[str]) -> str:
    """
    –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–≥ —Å —ç–º–æ–¥–∑–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–æ–≤–æ—Å—Ç–∏.
    """
    category = classify_category(title, summary)

    if category == "–º–æ–¥–µ–ª–∏ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –ò–ò":
        return "üß† –ú–æ–¥–µ–ª–∏ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"
    if category == "—Å—Ç–∞—Ä—Ç–∞–ø—ã –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ –ò–ò":
        return "üí∞ –°—Ç–∞—Ä—Ç–∞–ø—ã –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏"
    if category == "—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –ò–ò":
        return "‚öñÔ∏è –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å"
    if category == "–ø—Ä–∏–∫–ª–∞–¥–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –∏ —Å–µ—Ä–≤–∏—Å—ã –Ω–∞ –±–∞–∑–µ –ò–ò":
        return "üîß –ü—Ä–æ–¥—É–∫—Ç—ã –∏ —Å–µ—Ä–≤–∏—Å—ã"
    if category == "–ò–ò –≤ –º–µ–¥–∏—Ü–∏–Ω–µ":
        return "ü©∫ –ò–ò –≤ –º–µ–¥–∏—Ü–∏–Ω–µ"
    if category == "–ò–ò –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏":
        return "üìö –ò–ò –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏"

    return "üåç –¢—Ä–µ–Ω–¥—ã –ò–ò"


# ============ –ü–ê–†–°–ò–ù–ì RSS ============

def _fetch_rss(url: str, limit: int = 30) -> List[Dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–∞—Ä—Å–∏–º –æ–¥–Ω—É RSS-–ª–µ–Ω—Ç—É Google News."""
    logger.info("–ó–∞–≥—Ä—É–∂–∞—é RSS: %s", url)
    try:
        with urllib.request.urlopen(url, timeout=15) as resp:
            data = resp.read()
    except Exception as e:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å RSS %s: %s", url, e)
        return []

    try:
        root = ET.fromstring(data)
    except Exception as e:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å RSS %s: %s", url, e)
        return []

    channel_title = (
        root.findtext("./channel/title")
        or root.findtext(".//title")
        or "Google –ù–æ–≤–æ—Å—Ç–∏"
    )

    items: List[Dict] = []
    for item in root.findall(".//item"):
        title = item.findtext("title")
        link = item.findtext("link")
        desc_raw = item.findtext("description")

        if not title or not link:
            continue

        title = unescape(title.strip())
        link = link.strip()

        summary: Optional[str] = None
        if desc_raw:
            summary_clean = clean_html(desc_raw)
            if summary_clean:
                summary = shorten_summary(summary_clean, max_len=350)

        image: Optional[str] = None
        media_content = item.find("media:content", NS)
        if media_content is not None:
            image = media_content.get("url")

        if not image:
            thumb = item.find("media:thumbnail", NS)
            if thumb is not None:
                image = thumb.get("url")

        items.append(
            {
                "title": title,
                "url": link,
                "image": image,
                "source": channel_title,
                "summary": summary,
            }
        )

        if len(items) >= limit:
            break

    return items


def fetch_ai_news(limit: int = 100) -> List[Dict]:
    """
    –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –ò–ò –∏–∑ –≤—Å–µ—Ö RSS-–ª–µ–Ω—Ç.
    –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏ –ø–æ —Å—Å—ã–ª–∫–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–æ limit —à—Ç—É–∫.
    """
    all_items: List[Dict] = []
    for feed in RSS_FEEDS:
        all_items.extend(_fetch_rss(feed, limit=limit))

    seen_urls = set()
    result: List[Dict] = []
    for item in all_items:
        url = item["url"]
        if url in seen_urls:
            continue
        seen_urls.add(url)
        result.append(item)
        if len(result) >= limit:
            break

    logger.info("–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: %d", len(result))
    return result


def get_fresh_news(max_count: int = 3) -> List[Dict]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã—Ö –µ—â—ë –Ω–µ –±—ã–ª–æ –≤ POSTED_URLS.
    max_count ‚Äî –º–∞–∫—Å–∏–º—É–º –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥.
    """
    all_news = fetch_ai_news(limit=100)
    fresh: List[Dict] = []
    for item in all_news:
        if item["url"] in POSTED_URLS:
            continue
        fresh.append(item)
        if len(fresh) >= max_count:
            break

    return fresh


# ============ –û–¢–ß–Å–¢ –ê–î–ú–ò–ù–£ ============

async def notify_admin(context: ContextTypes.DEFAULT_TYPE, text: str) -> None:
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É, –µ—Å–ª–∏ ADMIN_ID –∑–∞–¥–∞–Ω."""
    if ADMIN_ID is None:
        return
    try:
        await context.bot.send_message(chat_id=ADMIN_ID, text=text)
    except Exception as e:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É: %s", e)


# ============ –ü–£–ë–õ–ò–ö–ê–¶–ò–Ø –û–î–ù–û–ô –ù–û–í–û–°–¢–ò ============

async def send_single_news(context: ContextTypes.DEFAULT_TYPE, item: Dict) -> None:
    """
    –ü—É–±–ª–∏–∫—É–µ—Ç –æ–¥–Ω—É –Ω–æ–≤–æ—Å—Ç—å –≤ –∫–∞–Ω–∞–ª:
    - —Ç–µ–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    - –∑–∞–≥–æ–ª–æ–≤–æ–∫
    - –∫—Ä–∞—Ç–∫–∏–π —Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
    - –∏—Å—Ç–æ—á–Ω–∏–∫-—Å—Å—ã–ª–∫–∞
    - –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî photo + caption
    """
    title = item["title"]
    url = item["url"]
    source = item["source"]
    summary = item.get("summary")
    image = item.get("image")

    safe_url = html_escape(url, quote=True)
    safe_source = html_escape(source, quote=True)

    tag = category_tag(title, summary)

    parts: List[str] = []

    # –¢–µ–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    parts.append(tag)
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    parts.append(f"üì∞ {html_escape(title, quote=False)}")

    # –ö—Ä–∞—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
    if summary:
        parts.append("")
        parts.append(html_escape(summary, quote=False))

    # –ò—Å—Ç–æ—á–Ω–∏–∫
    parts.append("")
    parts.append(f'üìé –ò—Å—Ç–æ—á–Ω–∏–∫: <a href="{safe_url}">{safe_source}</a>')

    text = "\n".join(parts)

    # –î–ª—è photo caption –ª–∏–º–∏—Ç 1024 —Å–∏–º–≤–æ–ª–∞ ‚Üí –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ä–µ–∂–µ–º
    def trim_for_caption(s: str, limit: int = 1024) -> str:
        if len(s) <= limit:
            return s
        return s[: limit - 3] + "‚Ä¶"

    if image:
        try:
            caption = trim_for_caption(text, 1024)
            await context.bot.send_photo(
                chat_id=CHANNEL_ID,
                photo=image,
                caption=caption,
                parse_mode="HTML",
            )
            return
        except Exception as e:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ (%s): %s, —à–ª—ë–º —Ç–µ–∫—Å—Ç–æ–º", image, e)

    # –¢–µ–∫—Å—Ç–æ–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
    if len(text) > 4096:
        text = text[:4090] + "‚Ä¶"

    await context.bot.send_message(
        chat_id=CHANNEL_ID,
        text=text,
        parse_mode="HTML",
        disable_web_page_preview=False,
    )


# ============ –ü–ï–†–ò–û–î–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê –ù–û–í–û–°–¢–ï–ô ============

async def check_and_post_news(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–∞–∂–¥—ã–µ N –º–∏–Ω—É—Ç:
    - –æ–±–Ω–æ–≤–ª—è–µ–º –¥–µ–Ω—å
    - –∏—â–µ–º –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
    - –ø—É–±–ª–∏–∫—É–µ–º –¥–æ 3 –Ω–æ–≤—ã—Ö —à—Ç—É–∫
    """
    reset_day_if_needed()

    try:
        fresh_news = get_fresh_news(max_count=3)
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π")
        await notify_admin(context, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return

    if not fresh_news:
        logger.info("–ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return

    for item in fresh_news:
        POSTED_URLS.add(item["url"])
        DAILY_ITEMS.append(item)
        try:
            await send_single_news(context, item)
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –Ω–æ–≤–æ—Å—Ç–∏")
            await notify_admin(
                context,
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –Ω–æ–≤–æ—Å—Ç–∏:\n{item.get('title')}\n{e}",
            )


# ============ –í–ï–ß–ï–†–ù–ò–ô –î–ê–ô–î–ñ–ï–°–¢ –í 21:00 ============

async def send_evening_digest(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –í 21:00 –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–∏–Ω –¥–∞–π–¥–∂–µ—Å—Ç –≤—Å–µ—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –¥–µ–Ω—å.
    –ë–µ–∑ –ò–ò-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, —Ç–æ–ª—å–∫–æ —Ç–µ–≥, –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∫—Ä–∞—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –∏ –∏—Å—Ç–æ—á–Ω–∏–∫.
    """
    reset_day_if_needed()

    if not DAILY_ITEMS:
        logger.info("–ó–∞ –¥–µ–Ω—å –Ω–µ –±—ã–ª–æ –Ω–æ–≤–æ—Å—Ç–µ–π, –¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º")
        await notify_admin(
            context,
            "‚ÑπÔ∏è –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç: –∑–∞ —Å–µ–≥–æ–¥–Ω—è –Ω–µ –±—ã–ª–æ –¥–Ω–µ–≤–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤, –¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.",
        )
        return

    lines: List[str] = []
    lines.append("üß† <b>–í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –ò–ò ‚Äî –≥–ª–∞–≤–Ω–æ–µ –∑–∞ —Å–µ–≥–æ–¥–Ω—è</b>\n")

    for i, item in enumerate(DAILY_ITEMS, start=1):
        title = item["title"]
        url = item["url"]
        source = item["source"]
        summary = item.get("summary")

        safe_url = html_escape(url, quote=True)
        safe_source = html_escape(source, quote=True)
        safe_title = html_escape(title, quote=False)
        safe_summary = html_escape(summary, quote=False) if summary else None
        tag = category_tag(title, summary)

        lines.append(f"{i}. {tag}")
        lines.append(f"   {safe_title}")
        if safe_summary:
            lines.append(f"   {safe_summary}")
        lines.append(f'   üìé <a href="{safe_url}">{safe_source}</a>')
        lines.append("")

    text = "\n".join(lines)

    await context.bot.send_message(
        chat_id=CHANNEL_ID,
        text=text,
        parse_mode="HTML",
        disable_web_page_preview=True,
    )

    DAILY_ITEMS.clear()
    logger.info("–í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω, DAILY_ITEMS –æ—á–∏—â–µ–Ω")


# ============ –ó–ê–ü–£–°–ö –ë–û–¢–ê ============

def main() -> None:
    app = Application.builder().token(TOKEN).build()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç
    app.job_queue.run_repeating(
        check_and_post_news,
        interval=15 * 60,  # 15 –º–∏–Ω—É—Ç
        first=30,          # –ø–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ 30 —Å–µ–∫—É–Ω–¥
        name="check-news",
    )

    # –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00
    app.job_queue.run_daily(
        send_evening_digest,
        time=time(21, 0, tzinfo=TZ),
        name="evening-digest",
    )

    logger.info(
        "AI News –±–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç, "
        "–≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00."
    )

    # –ë–æ—Ç –Ω–µ —Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ –∞–ø–¥–µ–π—Ç—ã, —Ç–æ–ª—å–∫–æ —Å–∞–º —à–ª—ë—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏ –¥–∞–π–¥–∂–µ—Å—Ç
    app.run_polling(allowed_updates=[])


if __name__ == "__main__":
    main()
