import os
import logging
from datetime import date
from zoneinfo import ZoneInfo

import feedparser
from openai import OpenAI
from telegram import Update
from telegram.constants import ParseMode
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    ContextTypes,
)

# ================== –õ–û–ì–ò ==================
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)

# ================== –ù–ê–°–¢–†–û–ô–ö–ò ==================
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
ADMIN_ID = os.getenv("ADMIN_ID")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TOKEN:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
if not CHANNEL_ID:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω CHANNEL_ID –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
if not ADMIN_ID:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω ADMIN_ID –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

CHANNEL_ID = int(CHANNEL_ID)
ADMIN_ID = int(ADMIN_ID)

USE_OPENAI = bool(OPENAI_API_KEY)
client: OpenAI | None = OpenAI(api_key=OPENAI_API_KEY) if USE_OPENAI else None

TZ = ZoneInfo("Asia/Dushanbe")

# –ê–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ –ò–ò (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å)
RSS_FEEDS = [
    # Google News –ø–æ –ò–ò (—Ä—É—Å/–∞–Ω–≥–ª)
    "https://news.google.com/rss/search?q=–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
    "https://news.google.com/rss/search?q=artificial+intelligence&hl=ru&gl=RU&ceid=RU:ru",

    # –ü—Ä–∏–º–µ—Ä—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏–∑–¥–∞–Ω–∏–π (–º–æ–≥—É—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ Google News, –Ω–æ —ç—Ç–æ –Ω–µ —Å—Ç—Ä–∞—à–Ω–æ)
    "https://habr.com/ru/rss/hub/machine_learning/all/?fl=ru",
    "https://forklog.com/news/ai/feed",  # ForkLog AI
]

# –£–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ ‚Äî —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏
POSTED_URLS: set[str] = set()

# –î–ª—è –≤–µ—á–µ—Ä–Ω–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞
TODAY_TITLES: list[str] = []
CURRENT_DAY: date = date.today()


# ================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ==================
def extract_image(entry) -> str | None:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –¥–æ—Å—Ç–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ RSS-–∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å.
    """
    media = getattr(entry, "media_content", None)
    if media and isinstance(media, list):
        url = media[0].get("url")
        if url:
            return url

    links = getattr(entry, "links", [])
    for l in links:
        if l.get("type", "").startswith("image/") and l.get("href"):
            return l["href"]

    return None


def ensure_new_day():
    """
    –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ –ø—Ä–∏ —Å–º–µ–Ω–µ –¥–Ω—è.
    """
    global CURRENT_DAY, TODAY_TITLES
    today = date.today()
    if today != CURRENT_DAY:
        CURRENT_DAY = today
        TODAY_TITLES = []


def fetch_raw_news(max_items: int = 5) -> list[dict]:
    """
    –°–æ–±–∏—Ä–∞–µ–º —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö RSS-–ª–µ–Ω—Ç.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π: title, summary, url, image, source.
    –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –µ—â—ë –Ω–µ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∏.
    """
    items: list[dict] = []

    for feed_url in RSS_FEEDS:
        try:
            parsed = feedparser.parse(feed_url)
        except Exception as e:
            logger.warning("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è RSS %s: %s", feed_url, e)
            continue

        source_title = parsed.feed.get("title", "–ù–æ–≤–æ—Å—Ç–∏ –ò–ò")

        for entry in parsed.entries:
            title = entry.get("title")
            link = entry.get("link")
            if not title or not link:
                continue

            if link in POSTED_URLS:
                continue

            summary = getattr(entry, "summary", "") or ""
            image = extract_image(entry)

            items.append(
                {
                    "title": title,
                    "summary": summary,
                    "url": link,
                    "image": image,
                    "source": source_title,
                }
            )

    # –ø—Ä–æ—Å—Ç–æ –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ max_items
    return items[:max_items]


def build_openai_prompt(title: str, summary: str, source: str) -> str:
    return f"""
–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä Telegram-–∫–∞–Ω–∞–ª–∞ –ø—Ä–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç.

–¢–µ–±–µ –¥–∞–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏, –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ RSS –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑–¥–∞–Ω–∏—è.
–°–¥–µ–ª–∞–π –û–î–ò–ù —Ç–µ–ª–µ–≥—Ä–∞–º-–ø–æ—Å—Ç –Ω–∞ –†–£–°–°–ö–û–ú:

1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏–¥—É–º–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π, –∂–∏–≤–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–Ω–µ –¥–ª–∏–Ω–Ω–µ–µ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏).
2. –ü–æ—Ç–æ–º –Ω–∞–ø–∏—à–∏ —Å–≤—è–∑–Ω—ã–π –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Ç–µ–∫—Å—Ç 4‚Äì7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.
3. –û–±—ä—è—Å–Ω–∏, —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ, –∫–æ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ –∏ –∫ —á–µ–º—É —ç—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏.
4. –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –¥–æ—Å–ª–æ–≤–Ω–æ –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫.
5. –ù–µ —É–ø–æ–º–∏–Ω–∞–π —Å—Å—ã–ª–∫—É, —Å–∞–π—Ç –∏ —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–ø–æ —Å—Å—ã–ª–∫–µ –Ω–∏–∂–µ" ‚Äî —Å—Å—ã–ª–∫–∞ –±—É–¥–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ.

–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

–ó–∞–≥–æ–ª–æ–≤–æ–∫: ...
–¢–µ–∫—Å—Ç: ...

---

–ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {summary}
–ò—Å—Ç–æ—á–Ω–∏–∫: {source}
""".strip()


def parse_openai_answer(raw: str, fallback_title: str) -> tuple[str, str]:
    """
    –†–∞–∑–±–∏—Ä–∞–µ–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ —Ñ–æ—Ä–º–∞—Ç–∞:
    –ó–∞–≥–æ–ª–æ–≤–æ–∫: ...
    –¢–µ–∫—Å—Ç: ...
    """
    title_ru = fallback_title
    body_ru = raw.strip()

    lines = raw.splitlines()
    current_section = None
    collected_body: list[str] = []

    for line in lines:
        line = line.strip()
        if line.lower().startswith("–∑–∞–≥–æ–ª–æ–≤–æ–∫:"):
            title_ru = line.split(":", 1)[1].strip() or fallback_title
            current_section = "title"
        elif line.lower().startswith("—Ç–µ–∫—Å—Ç:"):
            current_section = "body"
            rest = line.split(":", 1)[1].strip()
            if rest:
                collected_body.append(rest)
        else:
            if current_section == "body" and line:
                collected_body.append(line)

    if collected_body:
        body_ru = "\n".join(collected_body).strip()

    return title_ru, body_ru


def summarize_news_item(item: dict) -> tuple[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (title_ru, body_ru).
    –ï—Å–ª–∏ OPENAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ ‚Äî –¥–∞—ë–º –ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç.
    """
    title = item["title"]
    summary = item.get("summary") or ""
    source = item.get("source") or ""

    if not USE_OPENAI or client is None:
        # fallback: –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º title + summary
        simple_body = summary or title
        return title, simple_body

    prompt = build_openai_prompt(title, summary, source)

    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=500,
        )
        raw_answer = resp.choices[0].message.content.strip()
        return parse_openai_answer(raw_answer, fallback_title=title)
    except Exception as e:
        logger.warning("–û—à–∏–±–∫–∞ OpenAI: %s", e)
        simple_body = summary or title
        return title, simple_body


# ================== –û–¢–ü–†–ê–í–ö–ê –ù–û–í–û–°–¢–ï–ô ==================
async def publish_latest_news(bot, limit: int = 3) -> None:
    """
    –ò—â–µ–º —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –ø—É–±–ª–∏–∫—É–µ–º –¥–æ limit —à—Ç—É–∫ –≤ –∫–∞–Ω–∞–ª.
    """
    ensure_new_day()

    raw_items = fetch_raw_news(max_items=limit)
    if not raw_items:
        logger.info("–°–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return

    for item in raw_items:
        url = item["url"]
        if url in POSTED_URLS:
            continue

        title_ru, body_ru = summarize_news_item(item)

        text = f"üß† <b>{title_ru}</b>\n\n{body_ru}\n\n‚ûú <a href=\"{url}\">–ò—Å—Ç–æ—á–Ω–∏–∫</a>"

        try:
            if item.get("image"):
                await bot.send_photo(
                    chat_id=CHANNEL_ID,
                    photo=item["image"],
                    caption=text,
                    parse_mode=ParseMode.HTML,
                )
            else:
                await bot.send_message(
                    chat_id=CHANNEL_ID,
                    text=text,
                    parse_mode=ParseMode.HTML,
                )
        except Exception as e:
            logger.warning("–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: %s", e)
            # –µ—Å–ª–∏ —Å —Ñ–æ—Ç–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º —á–∏—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–º
            try:
                await bot.send_message(
                    chat_id=CHANNEL_ID,
                    text=text,
                    parse_mode=ParseMode.HTML,
                )
            except Exception as e2:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤–æ—Å—Ç—å –≤–æ–æ–±—â–µ: %s", e2)
                continue

        POSTED_URLS.add(url)
        TODAY_TITLES.append(title_ru)


async def send_daily_digest(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç: –∫–æ—Ä–æ—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ –≥–ª–∞–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–Ω—è.
    """
    ensure_new_day()

    if not TODAY_TITLES:
        logger.info("–ó–∞ —Å–µ–≥–æ–¥–Ω—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –±—ã–ª–æ ‚Äî –¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º")
        return

    lines = [f"{i}. {title}" for i, title in enumerate(TODAY_TITLES[:10], start=1)]
    text = "üìå <b>–í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –ò–ò</b>\n\n" \
           "–°–µ–≥–æ–¥–Ω—è –≤ –º–∏—Ä–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –ø—Ä–æ–∏–∑–æ—à–ª–æ –≥–ª–∞–≤–Ω–æ–µ:\n\n" + \
           "\n".join(lines) + \
           "\n\n–°–ø–∞—Å–∏–±–æ, —á—Ç–æ —á–∏—Ç–∞–µ—Ç–µ AI News Digest!"

    await context.bot.send_message(
        chat_id=CHANNEL_ID,
        text=text,
        parse_mode=ParseMode.HTML,
    )


# ================== –•–ï–ù–î–õ–ï–†–´ –ö–û–ú–ê–ù–î ==================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if update.effective_user.id != ADMIN_ID:
        return

    await update.message.reply_text(
        "ü§ñ AI News Bot –∑–∞–ø—É—â–µ–Ω.\n"
        "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω—ã."
    )


async def test(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if update.effective_user.id != ADMIN_ID:
        return

    await update.message.reply_text("–û–∫! –û—Ç–ø—Ä–∞–≤–ª—è—é —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –ø–æ—Å—Ç –≤ –∫–∞–Ω–∞–ª.")
    await publish_latest_news(context.bot, limit=1)


# ================== MAIN ==================
def main() -> None:
    app = ApplicationBuilder().token(TOKEN).build()

    # –ö–æ–º–∞–Ω–¥—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–±—è
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("test", test))

    # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî –∫–∞–∂–¥—ã–µ 60 –º–∏–Ω—É—Ç
    app.job_queue.run_repeating(
        lambda context: publish_latest_news(context.bot, limit=3),
        interval=60 * 60,
        first=30,  # —á–µ—Ä–µ–∑ 30 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞
    )

    # –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00
    app.job_queue.run_daily(
        send_daily_digest,
        time=time(21, 0, tzinfo=TZ),
        name="daily_digest",
    )

    logger.info("AI News Bot –∑–∞–ø—É—â–µ–Ω")
    app.run_polling(allowed_updates=["message"])


if __name__ == "__main__":
    from datetime import time

    main()
