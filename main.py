import os
import logging
from datetime import time, date
from zoneinfo import ZoneInfo
from typing import List, Dict, Optional
from html import unescape, escape as html_escape
import urllib.request
import xml.etree.ElementTree as ET

from telegram.ext import Application, ContextTypes

# ============ –õ–û–ì–ò ============
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)

# ============ –ü–ï–†–ï–ú–ï–ù–ù–´–ï –û–ö–†–£–ñ–ï–ù–ò–Ø ============
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID_ENV = os.getenv("CHANNEL_ID")
ADMIN_ID_ENV = os.getenv("ADMIN_ID")  # —Ç–≤–æ–π Telegram ID (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª–µ–Ω, –Ω–æ –ø–æ–ª–µ–∑–µ–Ω)

if not TOKEN:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
if not CHANNEL_ID_ENV:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω CHANNEL_ID –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

CHANNEL_ID = int(CHANNEL_ID_ENV)
ADMIN_ID: Optional[int] = int(ADMIN_ID_ENV) if ADMIN_ID_ENV else None

# –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–æ–Ω–∞ –î—É—à–∞–Ω–±–µ
TZ = ZoneInfo("Asia/Dushanbe")

# ============ –£–ú–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò –ò–ò-–ù–û–í–û–°–¢–ï–ô ============
RSS_FEEDS: List[str] = [
    # –ú–∏—Ä –ò–ò ‚Äî –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ —Ö–µ–¥–ª–∞–π–Ω—ã
    (
        "https://news.google.com/rss/search?q="
        "artificial+intelligence+OR+AI+model+OR+machine+learning"
        "+-crypto+-casino&hl=en-US&gl=US&ceid=US:en"
    ),
    # –ú–∏—Ä –ò–ò ‚Äî —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ —Ö–µ–¥–ª–∞–π–Ω—ã
    (
        "https://news.google.com/rss/search?q="
        "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç+OR+–ò–ò+–Ω–µ–π—Ä–æ—Å–µ—Ç–∏"
        "+-–∫–∞–∑–∏–Ω–æ+-–±—É–∫–º–µ–∫–µ—Ä&hl=ru&gl=RU&ceid=RU:ru"
    ),
    # –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ò–ò, LLM –∏ ChatGPT
    (
        "https://news.google.com/rss/search?q="
        "ChatGPT+OR+\"large+language+model\"+OR+\"–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π+–ò–ò\""
        "&hl=ru&gl=RU&ceid=RU:ru"
    ),
    # –ë–∏–∑–Ω–µ—Å –∏ —Å—Ç–∞—Ä—Ç–∞–ø—ã –≤ –ò–ò
    (
        "https://news.google.com/rss/search?q="
        "\"AI startup\"+OR+\"AI company\"+OR+\"–ò–ò\"+—Å—Ç–∞—Ä—Ç–∞–ø"
        "&hl=en-US&gl=US&ceid=US:en"
    ),
]

# namespace –¥–ª—è media:thumbnail / media:content
NS = {"media": "http://search.yahoo.com/mrss/"}

# ============ –ü–ê–ú–Ø–¢–¨ –ù–ê –î–ï–ù–¨ ============
CURRENT_DAY: date = date.today()
POSTED_URLS: set[str] = set()      # —á—Ç–æ —É–∂–µ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∏ (—á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å)
DAILY_ITEMS: List[Dict] = []       # –Ω–æ–≤–æ—Å—Ç–∏, –≤–æ—à–µ–¥—à–∏–µ –≤ –¥–Ω–µ–≤–Ω—ã–µ –ø–æ—Å—Ç—ã (–¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞)


def reset_day_if_needed() -> None:
    """–°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–∞–º—è—Ç—å, –µ—Å–ª–∏ –Ω–∞—á–∞–ª—Å—è –Ω–æ–≤—ã–π –¥–µ–Ω—å."""
    global CURRENT_DAY, POSTED_URLS, DAILY_ITEMS
    today = date.today()
    if today != CURRENT_DAY:
        logger.info("–ù–∞—Å—Ç—É–ø–∏–ª –Ω–æ–≤—ã–π –¥–µ–Ω—å, –æ—á–∏—â–∞—é –ø–∞–º—è—Ç—å –Ω–æ–≤–æ—Å—Ç–µ–π")
        CURRENT_DAY = today
        POSTED_URLS = set()
        DAILY_ITEMS = []


# ============ –ü–ê–†–°–ò–ù–ì RSS –ë–ï–ó feedparser ============
def _fetch_rss(url: str, limit: int = 30) -> List[Dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–∞—Ä—Å–∏–º –æ–¥–Ω—É RSS-–ª–µ–Ω—Ç—É Google News."""
    logger.info("–ó–∞–≥—Ä—É–∂–∞—é RSS: %s", url)
    try:
        with urllib.request.urlopen(url, timeout=15) as resp:
            data = resp.read()
    except Exception as e:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å RSS %s: %s", url, e)
        return []

    try:
        root = ET.fromstring(data)
    except Exception as e:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å RSS %s: %s", url, e)
        return []

    channel_title = (
        root.findtext("./channel/title")
        or root.findtext(".//title")
        or "Google –ù–æ–≤–æ—Å—Ç–∏"
    )

    items: List[Dict] = []
    for item in root.findall(".//item"):
        title = item.findtext("title")
        link = item.findtext("link")

        if not title or not link:
            continue

        title = unescape(title.strip())
        link = link.strip()

        # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É (–µ—Å–ª–∏ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –≤ –±—É–¥—É—â–µ–º)
        image: Optional[str] = None
        media_content = item.find("media:content", NS)
        if media_content is not None:
            image = media_content.get("url")

        if not image:
            thumb = item.find("media:thumbnail", NS)
            if thumb is not None:
                image = thumb.get("url")

        items.append(
            {
                "title": title,
                "url": link,
                "image": image,
                "source": channel_title,
            }
        )

        if len(items) >= limit:
            break

    return items


def fetch_ai_news(limit: int = 100) -> List[Dict]:
    """
    –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –ò–ò –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö RSS-–ª–µ–Ω—Ç.
    –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏ –ø–æ —Å—Å—ã–ª–∫–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–æ limit —à—Ç—É–∫.
    """
    all_items: List[Dict] = []
    for feed in RSS_FEEDS:
        all_items.extend(_fetch_rss(feed, limit=limit))

    seen_urls = set()
    result: List[Dict] = []
    for item in all_items:
        url = item["url"]
        if url in seen_urls:
            continue
        seen_urls.add(url)
        result.append(item)
        if len(result) >= limit:
            break

    logger.info("–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: %d", len(result))
    return result


def get_fresh_news(max_count: int = 3) -> List[Dict]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã—Ö –µ—â—ë –Ω–µ –±—ã–ª–æ –≤ POSTED_URLS.
    max_count ‚Äî –º–∞–∫—Å–∏–º—É–º –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥ (—á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–ø–∞–º–∏—Ç—å).
    """
    all_news = fetch_ai_news(limit=100)
    fresh: List[Dict] = []
    for item in all_news:
        if item["url"] in POSTED_URLS:
            continue
        fresh.append(item)
        if len(fresh) >= max_count:
            break

    return fresh


# ============ –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–û–ï ============
async def notify_admin(context: ContextTypes.DEFAULT_TYPE, text: str) -> None:
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É, –µ—Å–ª–∏ ADMIN_ID –∑–∞–¥–∞–Ω."""
    if ADMIN_ID is None:
        return
    try:
        await context.bot.send_message(chat_id=ADMIN_ID, text=text)
    except Exception as e:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É: %s", e)


async def send_single_news(context: ContextTypes.DEFAULT_TYPE, item: Dict) -> None:
    """
    –ü—É–±–ª–∏–∫—É–µ—Ç –æ–¥–Ω—É –Ω–æ–≤–æ—Å—Ç—å –≤ –∫–∞–Ω–∞–ª:
    - –∑–∞–≥–æ–ª–æ–≤–æ–∫
    - —Å—Ç—Ä–æ–∫–∞ —Å –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º
    """
    title = item["title"]
    url = item["url"]
    source = item["source"]

    safe_url = html_escape(url, quote=True)
    safe_source = html_escape(source, quote=True)

    text = (
        f"üì∞ {title}\n\n"
        f'üìé –ò—Å—Ç–æ—á–Ω–∏–∫: <a href="{safe_url}">{safe_source}</a>'
    )

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –¥–ª–∏–Ω–µ
    if len(text) > 4096:
        text = text[:4090] + "‚Ä¶"

    await context.bot.send_message(
        chat_id=CHANNEL_ID,
        text=text,
        parse_mode="HTML",
        disable_web_page_preview=False,  # –ø—É—Å—Ç—å Telegram —Å–∞–º –ø–æ–∫–∞–∂–µ—Ç –ø—Ä–µ–≤—å—é, –µ—Å–ª–∏ –µ—Å—Ç—å
    )


# ============ –ü–ï–†–ò–û–î–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê –ù–û–í–û–°–¢–ï–ô ============
async def check_and_post_news(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–∞–∂–¥—ã–µ N –º–∏–Ω—É—Ç:
    - –æ–±–Ω–æ–≤–ª—è–µ–º –¥–µ–Ω—å
    - –∏—â–µ–º –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
    - –ø—É–±–ª–∏–∫—É–µ–º –¥–æ 3 –Ω–æ–≤—ã—Ö —à—Ç—É–∫ —Å—Ä–∞–∑—É
    """
    reset_day_if_needed()

    try:
        fresh_news = get_fresh_news(max_count=3)
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π")
        await notify_admin(context, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return

    if not fresh_news:
        # –ø—Ä–æ—Å—Ç–æ –º–æ–ª—á–∏–º, –±–µ–∑ —Å–ø–∞–º–∞
        logger.info("–ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return

    for item in fresh_news:
        POSTED_URLS.add(item["url"])
        DAILY_ITEMS.append(item)
        try:
            await send_single_news(context, item)
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –Ω–æ–≤–æ—Å—Ç–∏")
            await notify_admin(
                context,
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –Ω–æ–≤–æ—Å—Ç–∏:\n{item.get('title')}\n{e}",
            )


# ============ –í–ï–ß–ï–†–ù–ò–ô –î–ê–ô–î–ñ–ï–°–¢ –í 21:00 ============
async def send_evening_digest(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –í 21:00 –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–∏–Ω –¥–∞–π–¥–∂–µ—Å—Ç –≤—Å–µ—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –¥–µ–Ω—å.
    """
    reset_day_if_needed()

    if not DAILY_ITEMS:
        logger.info("–ó–∞ –¥–µ–Ω—å –Ω–µ –±—ã–ª–æ –Ω–æ–≤–æ—Å—Ç–µ–π, –¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º")
        await notify_admin(
            context,
            "‚ÑπÔ∏è –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç: –∑–∞ —Å–µ–≥–æ–¥–Ω—è –Ω–µ –±—ã–ª–æ –¥–Ω–µ–≤–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤, –¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.",
        )
        return

    lines = ["üß† <b>–í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –ò–ò ‚Äî –≥–ª–∞–≤–Ω–æ–µ –∑–∞ —Å–µ–≥–æ–¥–Ω—è</b>\n"]
    for i, item in enumerate(DAILY_ITEMS, start=1):
        safe_url = html_escape(item["url"], quote=True)
        safe_source = html_escape(item["source"], quote=True)
        title = html_escape(item["title"], quote=False)

        lines.append(
            f"{i}. {title}\n"
            f'   üìé <a href="{safe_url}">{safe_source}</a>\n'
        )

    text = "\n".join(lines)

    await context.bot.send_message(
        chat_id=CHANNEL_ID,
        text=text,
        parse_mode="HTML",
        disable_web_page_preview=True,
    )

    # –ø–æ—Å–ª–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –æ—á–∏—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–ø–∏—Å–æ–∫ –¥–∞–π–¥–∂–µ—Å—Ç–∞,
    # POSTED_URLS –æ—Å—Ç–∞–≤–ª—è–µ–º, —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ö –≤ —Ç–æ—Ç –∂–µ –¥–µ–Ω—å
    DAILY_ITEMS.clear()
    logger.info("–í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∏ DAILY_ITEMS –æ—á–∏—â–µ–Ω")


# ============ MAIN ============

def main() -> None:
    app = Application.builder().token(TOKEN).build()

    # ‚úÖ –∫–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∏ —Å—Ä–∞–∑—É –ø–æ—Å—Ç–∏–º –Ω–æ–≤—ã–µ
    app.job_queue.run_repeating(
        check_and_post_news,
        interval=15 * 60,      # 15 –º–∏–Ω—É—Ç
        first=30,              # –ø–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ 30 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞
        name="check-news",
    )

    # ‚úÖ –æ–¥–∏–Ω –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00
    app.job_queue.run_daily(
        send_evening_digest,
        time=time(21, 0, tzinfo=TZ),
        name="evening-digest",
    )

    logger.info("AI News –±–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç, –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00.")
    app.run_polling(allowed_updates=[])  # –±–æ—Ç —Å–∞–º –Ω–µ —Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è, —Ç–æ–ª—å–∫–æ –∑–∞–¥–∞—á–∏


if __name__ == "__main__":
    main()
