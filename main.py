import os
import logging
from datetime import datetime, time
from zoneinfo import ZoneInfo
from html import escape as html_escape
import asyncio

import feedparser
from openai import OpenAI
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
)
from telegram import Update

# ================== –ù–ê–°–¢–†–û–ô–ö–ò ==================

TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID_RAW = os.getenv("CHANNEL_ID")
ADMIN_ID_RAW = os.getenv("ADMIN_ID")  # –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏

if not TELEGRAM_TOKEN:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
if not CHANNEL_ID_RAW:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω CHANNEL_ID –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

CHANNEL_ID = int(CHANNEL_ID_RAW)
ADMIN_ID = int(ADMIN_ID_RAW) if ADMIN_ID_RAW else None

# –í—Ä–µ–º—è –∏ —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å
DUSHANBE_TZ = ZoneInfo("Asia/Dushanbe")

# RSS-–ª–µ–Ω—Ç—ã –ø–æ –ò–ò (Google News —É–∂–µ —Ç—è–Ω–µ—Ç –º–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)
RSS_FEEDS = [
    # Google News –ø–æ –ò–ò –Ω–∞ —Ä—É—Å—Å–∫–æ–º
    "https://news.google.com/rss/search?q=–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
    # Google News –ø–æ –ò–ò –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (–º–∏—Ä–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏, –ø–æ—Ç–æ–º –ø–µ—Ä–µ–≤–æ–¥–∏–º / –ø–µ—Ä–µ—Å–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ —Ä—É—Å—Å–∫–æ–º)
    "https://news.google.com/rss/search?q=artificial+intelligence&hl=ru&gl=RU&ceid=RU:ru",
]

# –ö–∞–∫ —á–∞—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
NEWS_INTERVAL_SECONDS = 45 * 60  # –∫–∞–∂–¥—ã–µ ~45 –º–∏–Ω—É—Ç

# –°–∫–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –º–∞–∫—Å–∏–º—É–º –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥
MAX_NEWS_PER_RUN = 5

# –§–∞–π–ª, –≤ –∫–æ—Ç–æ—Ä–æ–º —Ö—Ä–∞–Ω–∏–º —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏
POSTED_LINKS_FILE = "posted_links.txt"

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger("ai-news-bot")

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ (–≤ —Ä–∞–º–∫–∞—Ö –∂–∏–∑–Ω–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞)
posted_links: set[str] = set()

# OpenAI-–∫–ª–∏–µ–Ω—Ç (–º–æ–∂–µ—Ç –±—ã—Ç—å None, –µ—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç)
openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None


# ================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ==================


def load_posted_links() -> None:
    """–ó–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)."""
    global posted_links
    try:
        if os.path.exists(POSTED_LINKS_FILE):
            with open(POSTED_LINKS_FILE, "r", encoding="utf-8") as f:
                for line in f:
                    url = line.strip()
                    if url:
                        posted_links.add(url)
        logger.info("–ó–∞–≥—Ä—É–∂–µ–Ω–æ %d —Å—Å—ã–ª–æ–∫ –∏–∑ —Ñ–∞–π–ª–∞", len(posted_links))
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ posted_links: %s", e)


def save_posted_links() -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ –≤ —Ñ–∞–π–ª (best effort)."""
    try:
        with open(POSTED_LINKS_FILE, "w", encoding="utf-8") as f:
            for url in posted_links:
                f.write(url + "\n")
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ posted_links: %s", e)


async def notify_admin(context: ContextTypes.DEFAULT_TYPE, text: str) -> None:
    """–ü–æ—Å–ª–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É –ø—Ä–∏ –æ—à–∏–±–∫–µ (–µ—Å–ª–∏ ID –∑–∞–¥–∞–Ω)."""
    if not ADMIN_ID:
        return
    try:
        await context.bot.send_message(chat_id=ADMIN_ID, text=text)
    except Exception:
        logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É")


def fetch_raw_entries() -> list[dict]:
    """–°–∫–∞—á–∞—Ç—å —Å—ã—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –≤—Å–µ—Ö RSS-–ª–µ–Ω—Ç."""
    items: list[dict] = []
    for feed_url in RSS_FEEDS:
        try:
            parsed = feedparser.parse(feed_url)
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ª–µ–Ω—Ç—ã %s: %s", feed_url, e)
            continue

        source_title = parsed.feed.get("title", "–ù–æ–≤–æ—Å—Ç–∏ –ò–ò")
        for entry in parsed.entries:
            title = entry.get("title")
            link = entry.get("link")
            if not title or not link:
                continue
            summary = entry.get("summary") or entry.get("description") or ""
            published = entry.get("published") or entry.get("updated") or ""

            items.append(
                {
                    "title": title,
                    "link": link,
                    "summary": summary,
                    "source": source_title,
                    "published": published,
                }
            )

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –ø–æ —Å—Å—ã–ª–∫–µ, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
    seen = set()
    unique_items: list[dict] = []
    for it in items:
        url = it["link"]
        if url in seen:
            continue
        seen.add(url)
        unique_items.append(it)

    return unique_items


def _build_openai_prompt(entry: dict) -> str:
    title = entry["title"]
    source = entry["source"]
    raw_summary = entry["summary"]

    return (
        "–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ç–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª–∞ –ø—Ä–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç.\n"
        "–°–¥–µ–ª–∞–π —Å–≤—è–∑–Ω—ã–π –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
        "–ü–∏—à–∏ –≤ —Å—Ç–∏–ª–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –¥–µ–ª–æ–≤–æ–π –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–∏–∫–∏, –±–µ–∑ –≤–æ–¥—ã.\n\n"
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n"
        "‚Ä¢ 5‚Äì8 –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\n"
        "‚Ä¢ –ë–µ–∑ HTML, –±–µ–∑ —Å—Å—ã–ª–æ–∫, –±–µ–∑ —Å–ª–æ–≤ –≤—Ä–æ–¥–µ ¬´—ç—Ç–∞ –Ω–æ–≤–æ—Å—Ç—å¬ª, ¬´–¥–∞–Ω–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª¬ª.\n"
        "‚Ä¢ –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ—Å–ª–æ–≤–Ω–æ, –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∏ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä—É–π.\n"
        "‚Ä¢ –ù–µ —É–ø–æ–º–∏–Ω–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏ Google News, —Ç–æ–ª—å–∫–æ —Å—É—Ç—å —Å–æ–±—ã—Ç–∏—è.\n\n"
        f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}\n"
        f"–ò—Å—Ç–æ—á–Ω–∏–∫ (–¥–ª—è –æ—Ä–∏–µ–Ω—Ç–∏—Ä–∞, –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –≤ —Ç–µ–∫—Å—Ç–µ): {source}\n"
        f"–¢–µ–∫—Å—Ç/–∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –∏–∑ –ª–µ–Ω—Ç—ã:\n{raw_summary}\n"
    )


def summarize_with_openai_sync(entry: dict) -> str | None:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ OpenAI –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–ª–∏ None."""
    if not openai_client:
        return None

    try:
        prompt = _build_openai_prompt(entry)
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –æ–± –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ. "
                        "–ü–∏—à–µ—à—å –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É –∏ –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Ñ—Ä–∞–∑."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            max_tokens=400,
            temperature=0.4,
        )
        text = response.choices[0].message.content
        return text.strip() if text else None
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: %s", e)
        return None


async def build_news_text(entry: dict) -> str:
    """
    –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω–µ—á–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è:
    - –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–∂–∏—Ä–Ω—ã–π)
    - –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑ –Ω–∞ —Ä—É—Å—Å–∫–æ–º (OpenAI –∏–ª–∏ fallback)
    - ‚ûú –ò—Å—Ç–æ—á–Ω–∏–∫ (–∫–ª–∏–∫–∞–±–µ–ª—å–Ω–æ)
    """
    title = entry["title"]
    link = entry["link"]
    source = entry["source"]
    raw_summary = entry["summary"] or title

    # 1) –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑ —á–µ—Ä–µ–∑ OpenAI –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    summary = await asyncio.to_thread(summarize_with_openai_sync, entry)

    # 2) Fallback, –µ—Å–ª–∏ OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ
    if not summary:
        # –ü—Ä–∏–º–µ—Ä–Ω—ã–π fallback: –±–µ—Ä—ë–º summary, —á—É—Ç—å ¬´–æ—á–µ–ª–æ–≤–µ—á–∏–≤–∞–µ–º¬ª
        summary = raw_summary
        if len(summary) < 40:
            # –°–æ–≤—Å–µ–º –∫–æ—Ä–æ—Ç–∫–∞—è —à—Ç—É–∫–∞ ‚Äî –ø—Ä–æ—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            summary = f"{title}"
        else:
            # –ù–µ–º–Ω–æ–≥–æ —á–∏—Å—Ç–∫–∏ HTML —Å—É—â–Ω–æ—Å—Ç–µ–π, –Ω–æ –±–µ–∑ —Ç—è–∂—ë–ª–æ–π –ª–æ–≥–∏–∫–∏
            summary = summary.replace("&nbsp;", " ").replace("&amp;", "&")

    # 3) –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –¥–ª—è HTML, —á—Ç–æ–±—ã –Ω–µ —Å–ª–æ–º–∞—Ç—å parse_mode="HTML"
    safe_title = html_escape(title)
    safe_summary = html_escape(summary)
    safe_link = html_escape(link, quote=True)
    safe_source = html_escape(source)

    text = (
        f"üß† <b>{safe_title}</b>\n\n"
        f"{safe_summary}\n\n"
        f"‚ûú <a href=\"{safe_link}\">–ò—Å—Ç–æ—á–Ω–∏–∫</a> ({safe_source})"
    )
    return text


# ================== –ó–ê–î–ê–ß–ò JOB_QUEUE ==================


async def periodic_news_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞:
    - —Å–º–æ—Ç—Ä–∏–º —Å–≤–µ–∂–∏–µ –∑–∞–ø–∏—Å–∏ –∏–∑ RSS
    - –æ—Ç–±–∏—Ä–∞–µ–º —Ç–µ, —á—Ç–æ –µ—â—ë –Ω–µ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∏
    - –ø—É–±–ª–∏–∫—É–µ–º 1‚Äì5 –Ω–æ–≤—ã—Ö —à—Ç—É–∫ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
    """
    logger.info("–ó–∞–ø—É—Å–∫ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏ –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º")

    try:
        entries = fetch_raw_entries()
        logger.info("–ü–æ–ª—É—á–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π –∏–∑ RSS", len(entries))

        new_entries: list[dict] = []
        for e in entries:
            url = e["link"]
            if url in posted_links:
                continue
            new_entries.append(e)

        if not new_entries:
            logger.info("–ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—É—Å–∫
        new_entries = new_entries[:MAX_NEWS_PER_RUN]

        for entry in new_entries:
            url = entry["link"]
            try:
                text = await build_news_text(entry)

                await context.bot.send_message(
                    chat_id=CHANNEL_ID,
                    text=text,
                    parse_mode="HTML",
                    disable_web_page_preview=False,  # —Ö–æ—Ç–∏–º –∫—Ä–∞—Å–∏–≤—ã–µ –ø—Ä–µ–≤—å—é —Å –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏
                )

                posted_links.add(url)
                logger.info("–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å: %s", url)

            except Exception as e:
                logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –Ω–æ–≤–æ—Å—Ç–∏: %s", e)
                await notify_admin(
                    context,
                    f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –Ω–æ–≤–æ—Å—Ç–∏:\n{e}",
                )

        # –ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫
        save_posted_links()

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤–Ω—É—Ç—Ä–∏ periodic_news_job: %s", e)
        await notify_admin(context, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–µ –Ω–æ–≤–æ—Å—Ç–µ–π:\n{e}")


async def daily_digest_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00 (–ø–æ –î—É—à–∞–Ω–±–µ):
    - –±–µ—Ä—ë–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ RSS
    - –≤—ã–±–∏—Ä–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö
    - –¥–µ–ª–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ–±–∑–æ—Ä –≤ –æ–¥–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
    """
    logger.info("–ó–∞–ø—É—Å–∫ –≤–µ—á–µ—Ä–Ω–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞")

    try:
        entries = fetch_raw_entries()
        if not entries:
            logger.info("–î–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç")
            return

        # –û—Ç–±–µ—Ä—ë–º —Ç–æ–ø-3‚Äì5
        top_entries = entries[:5]

        digest_parts: list[str] = []
        for i, e in enumerate(top_entries, start=1):
            title = e["title"]
            source = e["source"]
            link = e["link"]

            safe_title = html_escape(title)
            safe_source = html_escape(source)
            safe_link = html_escape(link, quote=True)

            digest_parts.append(
                f"{i}. <b>{safe_title}</b>\n"
                f"   <i>{safe_source}</i>\n"
                f"   ‚ûú <a href=\"{safe_link}\">–ò—Å—Ç–æ—á–Ω–∏–∫</a>"
            )

        digest_text = (
            "üåô <b>–í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –ò–ò</b>\n\n"
            "–ü–æ–¥–±–æ—Ä–∫–∞ –∑–∞–º–µ—Ç–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –¥–µ–Ω—å:\n\n"
            + "\n\n".join(digest_parts)
        )

        await context.bot.send_message(
            chat_id=CHANNEL_ID,
            text=digest_text,
            parse_mode="HTML",
            disable_web_page_preview=False,
        )

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: %s", e)
        await notify_admin(context, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –≤–µ—á–µ—Ä–Ω–µ–º –¥–∞–π–¥–∂–µ—Å—Ç–µ:\n{e}")


# ================== –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î ==================


async def start_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    /start ‚Äî —á–∏—Å—Ç–æ —Å–µ—Ä–≤–∏—Å–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –±–æ—Ç –∂–∏–≤.
    –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∏ —Ç–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Render.
    """
    if update.effective_chat is None:
        return

    msg = (
        "ü§ñ –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –∫–∞–Ω–∞–ª–∞ <b>AI News Digest | –ò–ò –ù–æ–≤–æ—Å—Ç–∏</b>.\n\n"
        "–ù–æ–≤–æ—Å—Ç–∏ –æ–± –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ –ø—É–±–ª–∏–∫—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ "
        "–≤ —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è, –∞ –≤ 21:00 –ø–æ –î—É—à–∞–Ω–±–µ –≤—ã—Ö–æ–¥–∏—Ç –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç.\n\n"
        "–ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –∞–≤—Ç–æ—Ä—É –ø—Ä–∏–¥—ë—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ."
    )

    await update.message.reply_text(msg, parse_mode="HTML")


# ================== MAIN ==================


def main() -> None:
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞
    load_posted_links()

    # –°–æ–∑–¥–∞—ë–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ PTB v21
    application = Application.builder().token(TELEGRAM_TOKEN).build()

    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É /start
    application.add_handler(CommandHandler("start", start_handler))

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∑–∞–¥–∞—á–∏ JobQueue
    job_queue = application.job_queue

    # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (–ø–æ —Ö–æ–¥—É –¥–Ω—è)
    job_queue.run_repeating(
        periodic_news_job,
        interval=NEWS_INTERVAL_SECONDS,
        first=30,  # –ø–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ 30 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞
        name="periodic_news",
    )

    # –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00 –ø–æ –î—É—à–∞–Ω–±–µ
    job_queue.run_daily(
        daily_digest_job,
        time=time(21, 0, tzinfo=DUSHANBE_TZ),
        name="daily_digest",
    )

    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º polling")
    # –í–ê–ñ–ù–û: –æ–¥–∏–Ω —Ä–∞–∑, –±–µ–∑ asyncio.run, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ 'event loop is already running'
    application.run_polling(allowed_updates=[])


if __name__ == "__main__":
    main()
