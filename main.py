import os
import logging
import html
from datetime import time
from zoneinfo import ZoneInfo
from urllib.parse import urlparse
from urllib.request import urlopen
import xml.etree.ElementTree as ET

from telegram import Update
from telegram.constants import ParseMode
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
)

# ================= –ù–ê–°–¢–†–û–ô–ö–ò –û–ö–†–£–ñ–ï–ù–ò–Ø =================

TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID_ENV = os.getenv("CHANNEL_ID")
ADMIN_ID_ENV = os.getenv("ADMIN_ID")  # —Ç–≤–æ–π –ª–∏—á–Ω—ã–π Telegram ID (–¥–ª—è –æ—à–∏–±–æ–∫)

if not TOKEN:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

if not CHANNEL_ID_ENV:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω CHANNEL_ID –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

try:
    CHANNEL_ID = int(CHANNEL_ID_ENV)
except ValueError:
    raise RuntimeError("CHANNEL_ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ü–µ–ª—ã–º —á–∏—Å–ª–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä -1001234567890)")

ADMIN_ID = None
if ADMIN_ID_ENV:
    try:
        ADMIN_ID = int(ADMIN_ID_ENV)
    except ValueError:
        # –µ—Å–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —É–∫–∞–∑–∞–ª–∏, –ø—Ä–æ—Å—Ç–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º
        ADMIN_ID = None

# ================= –ò–°–¢–û–ß–ù–ò–ö–ò –ù–û–í–û–°–¢–ï–ô =================
# –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å —Å–≤–æ–∏ RSS-–ª–µ–Ω—Ç—ã –ø—Ä–æ –ò–ò

RSS_FEEDS = [
    # Google News –ø–æ –∑–∞–ø—Ä–æ—Å—É "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç" (—Ä—É—Å)
    "https://news.google.com/rss/search?q=–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π+–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç&hl=ru&gl=RU&ceid=RU:ru",
    # Google News –ø–æ –∑–∞–ø—Ä–æ—Å—É "artificial intelligence" (–∞–Ω–≥–ª, –Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ —á–∞—Å—Ç–æ –Ω–∞ –∞–Ω–≥–ª)
    "https://news.google.com/rss/search?q=artificial+intelligence&hl=ru&gl=RU&ceid=RU:ru",
]

# –ß—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏
posted_urls = set()


# ================= –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò =================

def fetch_url(url: str, timeout: int = 10) -> bytes:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ URL."""
    with urlopen(url, timeout=timeout) as resp:
        return resp.read()


def strip_html(text: str) -> str:
    """–ì—Ä—É–±–∞—è –æ—á–∏—Å—Ç–∫–∞ HTML –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è RSS."""
    import re

    if not text:
        return ""
    # —É–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏
    clean = re.sub(r"<[^>]+>", " ", text)
    # –¥–µ–∫–æ–¥–∏—Ä—É–µ–º HTML-—Å—É—â–Ω–æ—Å—Ç–∏
    clean = html.unescape(clean)
    # —Å–∂–∏–º–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    clean = " ".join(clean.split())
    return clean


def parse_rss(url: str):
    """
    –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ø–∞—Ä—Å–µ—Ä RSS.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π: title, url, summary, image.
    """
    items = []
    try:
        raw = fetch_url(url)
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RSS %s: %s", url, e)
        return items

    try:
        root = ET.fromstring(raw)
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ XML %s: %s", url, e)
        return items

    for item in root.findall(".//item"):
        title = (item.findtext("title") or "").strip()
        link = (item.findtext("link") or "").strip()
        description = (item.findtext("description") or "").strip()

        if not title or not link:
            continue

        summary = strip_html(description)

        # –ö–∞—Ä—Ç–∏–Ω–∫–∞, –µ—Å–ª–∏ –µ—Å—Ç—å <enclosure type="image/*" url="...">
        image_url = None
        enclosure = item.find("enclosure")
        if enclosure is not None and enclosure.get("type", "").startswith("image"):
            image_url = enclosure.get("url")

        items.append(
            {
                "title": title,
                "url": link,
                "summary": summary,
                "image": image_url,
            }
        )

    return items


def fetch_ai_news(max_items: int = 5):
    """
    –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö RSS-–ª–µ–Ω—Ç,
    —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –ø–æ URL –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ max_items —à—Ç—É–∫.
    """
    all_items = []

    for feed in RSS_FEEDS:
        parsed = parse_rss(feed)
        for item in parsed:
            # —É–±–∏—Ä–∞–µ–º —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ
            if item["url"] in posted_urls:
                continue
            all_items.append(item)

    unique = []
    seen = set()
    for it in all_items:
        url = it["url"]
        if url in seen:
            continue
        seen.add(url)
        unique.append(it)
        if len(unique) >= max_items:
            break

    return unique


def build_source_line(url: str) -> str:
    """
    –°—Ç—Ä–æ–∫–∞ –≤–∏–¥–∞:
    ‚û°Ô∏è –ò—Å—Ç–æ—á–Ω–∏–∫: <a href="...">rbc.ru</a>
    –ù–∏–∫–∞–∫–∏—Ö ¬´–ü–æ–¥—Ä–æ–±–Ω–µ–µ¬ª, ¬´Google –ù–æ–≤–æ—Å—Ç–∏¬ª –∏ —Ç.–ø.
    """
    parsed = urlparse(url)
    host = parsed.netloc or "–∏—Å—Ç–æ—á–Ω–∏–∫"
    if host.startswith("www."):
        host = host[4:]

    safe_url = html.escape(url, quote=True)
    safe_host = html.escape(host)

    return f'‚û°Ô∏è –ò—Å—Ç–æ—á–Ω–∏–∫: <a href="{safe_url}">{safe_host}</a>'


async def send_single_news(
    context: ContextTypes.DEFAULT_TYPE,
    item: dict,
    prefix_emoji: str = "üß†",
) -> None:
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –≤ –∫–∞–Ω–∞–ª:
    - –∂–∏—Ä–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    - –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    - –≤ –∫–æ–Ω—Ü–µ —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∞ —Å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º
    """
    title = html.escape(item["title"])

    summary = item.get("summary") or ""
    # —Ä–µ–∂–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –ø—Ä–æ—Å—Ç—ã–Ω–µ–π
    if len(summary) > 700:
        summary = summary[:700].rsplit(" ", 1)[0] + "‚Ä¶"
    summary = html.escape(summary)

    source_line = build_source_line(item["url"])

    text = f"{prefix_emoji} <b>{title}</b>\n\n{summary}\n\n{source_line}"

    # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å —Ñ–æ—Ç–æ
    image_url = item.get("image")
    if image_url:
        try:
            await context.bot.send_photo(
                chat_id=CHANNEL_ID,
                photo=image_url,
                caption=text,
                parse_mode=ParseMode.HTML,
            )
            return
        except Exception as e:
            logging.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ: %s. –ü–∞–¥–∞–µ–º –≤ —Ç–µ–∫—Å—Ç.", e)

    # –¢–µ–∫—Å—Ç–æ–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
    await context.bot.send_message(
        chat_id=CHANNEL_ID,
        text=text,
        parse_mode=ParseMode.HTML,
    )


# ================= JOB'–´ =================

async def auto_news_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –ø–æ—Å—Ç–∏–Ω–≥ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è.
    –ü—Ä–æ–≤–µ—Ä—è–µ–º RSS, –±–µ—Ä—ë–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º.
    """
    news = fetch_ai_news(max_items=3)
    if not news:
        logging.info("–°–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π —Å–µ–π—á–∞—Å –Ω–µ—Ç.")
        return

    for item in news:
        url = item["url"]
        posted_urls.add(url)
        await send_single_news(context, item, prefix_emoji="ü§ñ")


async def daily_digest_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00 ‚Äî –∫—Ä–∞—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏ —Å—Å—ã–ª–∫–∞–º–∏.
    """
    news = fetch_ai_news(max_items=5)
    if not news:
        await context.bot.send_message(
            chat_id=CHANNEL_ID,
            text="–°–µ–≥–æ–¥–Ω—è –Ω–µ –Ω–∞—à–ª–æ—Å—å –¥–æ—Å—Ç–æ–π–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –ò–ò.",
        )
        return

    lines = ["ü§ñ –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –ò–ò", ""]
    for i, item in enumerate(news, start=1):
        title = html.escape(item["title"])
        source_line = build_source_line(item["url"])
        lines.append(f"{i}. {title}")
        lines.append(source_line)
        lines.append("")

        posted_urls.add(item["url"])

    text = "\n".join(lines).strip()

    await context.bot.send_message(
        chat_id=CHANNEL_ID,
        text=text,
        parse_mode=ParseMode.HTML,
    )


# ================= –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î =================

async def start_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(
        "ü§ñ AI News Bot –∑–∞–ø—É—â–µ–Ω.\n"
        "–ë—É–¥—É –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –æ–± –ò–ò –≤ –∫–∞–Ω–∞–ª –∏ –¥–µ–ª–∞—Ç—å –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00."
    )


async def test_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    /test ‚Äî –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–¥–Ω—É —Ç–µ—Å—Ç–æ–≤—É—é –Ω–æ–≤–æ—Å—Ç—å –≤ –∫–∞–Ω–∞–ª.
    –£–¥–æ–±–Ω–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —á—Ç–æ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç.
    """
    news = fetch_ai_news(max_items=1)
    if not news:
        await update.message.reply_text("–°–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ–∫–∞ –Ω–µ –Ω–∞—à–ª–æ—Å—å.")
        return

    item = news[0]
    posted_urls.add(item["url"])
    await send_single_news(context, item, prefix_emoji="üß™")
    await update.message.reply_text("–¢–µ—Å—Ç–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ –∫–∞–Ω–∞–ª.")


# ================= –û–ë–†–ê–ë–û–¢–ß–ò–ö –û–®–ò–ë–û–ö =================

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    logging.exception("–û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ: %s", context.error)

    if ADMIN_ID is None:
        return

    try:
        text = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –±–æ—Ç–µ: {repr(context.error)}"
        await context.bot.send_message(chat_id=ADMIN_ID, text=text)
    except Exception:
        logging.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")


# ================= –ó–ê–ü–£–°–ö –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø =================

def main() -> None:
    logging.basicConfig(
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        level=logging.INFO,
    )

    app = Application.builder().token(TOKEN).build()

    # –ö–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", start_cmd))
    app.add_handler(CommandHandler("test", test_cmd))

    # –û—à–∏–±–∫–∏
    app.add_error_handler(error_handler)

    # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
    tz = ZoneInfo("Asia/Dushanbe")

    # –ê–≤—Ç–æ–Ω–æ–≤–æ—Å—Ç–∏ –≤ —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è ‚Äî –∫–∞–∂–¥—ã–µ 60 –º–∏–Ω—É—Ç
    app.job_queue.run_repeating(
        auto_news_job,
        interval=60 * 60,   # 1 —á–∞—Å
        first=30,           # –ø–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ 30 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞
        name="auto_news",
    )

    # –í–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ 21:00
    app.job_queue.run_daily(
        daily_digest_job,
        time=time(21, 0, tzinfo=tz),
        name="daily_digest",
    )

    # –ó–∞–ø—É—Å–∫–∞–µ–º long polling
    app.run_polling(allowed_updates=["message"])


if __name__ == "__main__":
    main()
