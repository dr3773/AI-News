import os
import logging
import re
from html import unescape, escape
from datetime import datetime
from zoneinfo import ZoneInfo
from typing import List, Dict, Set

import feedparser
from telegram import Update
from telegram.constants import ParseMode
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
)

# –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å OpenAI (–¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞)
try:
    from openai import OpenAI  # openai>=1.0.0
except ImportError:
    OpenAI = None

# ==========================
#        –ù–ê–°–¢–†–û–ô–ö–ò
# ==========================

TOKEN = (
    os.environ.get("TELEGRAM_BOT_TOKEN")
    or os.environ.get("BOT_TOKEN")
    or os.environ.get("TOKEN")
)

CHANNEL_ID = os.environ.get("CHANNEL_ID")
ADMIN_ID = os.environ.get("ADMIN_ID")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

if not TOKEN:
    raise RuntimeError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω TELEGRAM_BOT_TOKEN / BOT_TOKEN / TOKEN!")
if not CHANNEL_ID:
    raise RuntimeError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω CHANNEL_ID!")

TZ = ZoneInfo("Asia/Dushanbe")

# –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π (—Å–µ–∫—É–Ω–¥—ã)
NEWS_INTERVAL = int(os.environ.get("NEWS_INTERVAL", "1800"))  # 30 –º–∏–Ω—É—Ç
# –º–∞–∫—Å–∏–º—É–º –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –æ–¥–∏–Ω —Ü–∏–∫–ª (—á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å flood control)
MAX_POSTS_PER_RUN = 5

# RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî RU + EN
FEED_URLS: List[str] = [
    # —Ä—É—Å—Å–∫–∏–µ
    "https://news.yandex.ru/computers.rss",
    "https://news.yandex.ru/science.rss",
    "https://lenta.ru/rss/news",
    "https://ria.ru/export/rss2/science/index.xml",
    "https://habr.com/ru/rss/all/all/",
    "https://www.cnews.ru/inc/rss/news.xml",
    # –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ (–º–Ω–æ–≥–æ –ò–ò)
    "https://blog.google/technology/ai/rss/",
    "https://openai.com/blog/rss.xml",
    "https://techcrunch.com/tag/artificial-intelligence/feed/",
    "https://venturebeat.com/category/ai/feed/",
    "https://www.technologyreview.com/feed/",
]

# –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ò–ò-–Ω–æ–≤–æ—Å—Ç–µ–π
AI_KEYWORDS = [
    "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
    "–Ω–µ–π—Ä–æ—Å–µ—Ç",
    "–º–∞—à–∏–Ω–Ω",  # –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    "—Ä–æ–±–æ—Ç",
    "—á–∞—Ç–∏–±–æ—Ç",
    "—á–∞—Ç-–±–æ—Ç",
    "–ò–ò ",
    " AI",
    "artificial intelligence",
    "machine learning",
    "deep learning",
    "neural network",
    "neural-net",
    "ml ",
    "llm",
    "chatgpt",
    "gpt-",
]

# —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
SENT_URLS_FILE = "sent_urls.json"
sent_urls: Set[str] = set()

# ==========================
#          –õ–û–ì–ò
# ==========================

logging.basicConfig(
    format="%(asctime)s ‚Äî %(name)s ‚Äî %(levelname)s ‚Äî %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger("ai-news-bot")

# ==========================
#  OpenAI –∫–ª–∏–µ–Ω—Ç (–ø–µ—Ä–µ–≤–æ–¥)
# ==========================

if OPENAI_API_KEY and OpenAI is not None:
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
else:
    openai_client = None


def has_cyrillic(text: str) -> bool:
    return bool(re.search(r"[–ê-–Ø–∞-—è–Å—ë]", text or ""))


def translate_to_russian(text: str) -> str:
    """
    –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π.
    –ï—Å–ª–∏ OpenAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.
    """
    text = (text or "").strip()
    if not text:
        return ""

    # –µ—Å–ª–∏ —É–∂–µ —Ä—É—Å—Å–∫–∏–π ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
    if has_cyrillic(text):
        return text

    if not openai_client:
        return text  # –Ω–µ—Ç –∫–ª—é—á–∞ / –±–∏–±–ª–∏–æ—Ç–µ–∫–∏

    try:
        resp = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "–¢—ã –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫. –ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å–º—ã—Å–ª—É, –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥–æ–º.",
                },
                {"role": "user", "content": text},
            ],
            temperature=0.2,
            max_tokens=300,
        )
        result = resp.choices[0].message.content.strip()
        return result or text
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —á–µ—Ä–µ–∑ OpenAI: %s", e)
        return text


# ==========================
#     –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï
# ==========================


def clean_html(text: str) -> str:
    """–£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
    if not text:
        return ""
    text = unescape(text)
    text = re.sub(r"<.*?>", "", text)
    return text.strip()


def load_sent_urls() -> None:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞."""
    import json
    global sent_urls

    if not os.path.exists(SENT_URLS_FILE):
        sent_urls = set()
        return

    try:
        with open(SENT_URLS_FILE, "r", encoding="utf-8") as f:
            sent_urls = set(json.load(f))
        logger.info("–ó–∞–≥—Ä—É–∂–µ–Ω–æ %d –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫.", len(sent_urls))
    except Exception as e:
        logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å %s: %s", SENT_URLS_FILE, e)
        sent_urls = set()


def save_sent_urls() -> None:
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏."""
    import json
    try:
        with open(SENT_URLS_FILE, "w", encoding="utf-8") as f:
            json.dump(sorted(sent_urls), f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫: %s", e)


async def notify_admin(context: ContextTypes.DEFAULT_TYPE, text: str):
    if not ADMIN_ID:
        return
    try:
        await context.bot.send_message(chat_id=ADMIN_ID, text=f"‚ö†Ô∏è {text}")
    except Exception:
        logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É.")


# ==========================
#      –ü–ê–†–°–ò–ù–ì –ù–û–í–û–°–¢–ï–ô
# ==========================


def is_ai_news(title: str, summary: str) -> bool:
    """–§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ò–ò/ML –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º."""
    text = f"{title} {summary}".lower()
    return any(kw in text for kw in AI_KEYWORDS)


def fetch_news() -> List[Dict]:
    """–ß–∏—Ç–∞–µ–º RSS-–ª–µ–Ω—Ç—ã –∏ —Å–æ–±–∏—Ä–∞–µ–º –ù–ï–û–¢–ü–†–ê–í–õ–ï–ù–ù–´–ï –ò–ò-–Ω–æ–≤–æ—Å—Ç–∏."""
    items: List[Dict] = []

    for feed_url in FEED_URLS:
        try:
            feed = feedparser.parse(feed_url)
            for entry in feed.entries:
                link = entry.get("link")
                if not link or link in sent_urls:
                    continue

                title_raw = entry.get("title", "").strip()
                summary_raw = entry.get("summary", "") or entry.get("description", "")

                title_clean = clean_html(title_raw)
                summary_clean = clean_html(summary_raw)

                if not is_ai_news(title_clean, summary_clean):
                    continue  # –Ω–µ –ø—Ä–æ –ò–ò ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º

                items.append(
                    {
                        "title": title_clean,
                        "summary": summary_clean,
                        "url": link,
                    }
                )
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ RSS %s: %s", feed_url, e)

    return items


def build_body_text(title: str, summary: str) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏.
    - –ï—Å–ª–∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ü–£–°–¢–£–Æ —Å—Ç—Ä–æ–∫—É.
    - –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º ‚Äî –ø–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π.
    - –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ù–ï –¥—É–±–ª–∏—Ä—É–µ–º.
    """
    title_clean = (title or "").strip()
    summary_clean = (summary or "").strip()

    if not summary_clean:
        return ""

    # –µ—Å–ª–∏ summary –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞ ‚Äî —Å—á–∏—Ç–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    if summary_clean.lower().startswith(title_clean.lower()):
        return ""

    # –ø–µ—Ä–µ–≤–æ–¥–∏–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    result = translate_to_russian(summary_clean)
    return result.strip()


def build_post_text(item: Dict) -> str:
    """–°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ –¥–ª—è Telegram."""
    title = item["title"]
    summary = item["summary"]
    url = item["url"]

    body = build_body_text(title, summary)

    safe_title = escape(title)
    safe_url = escape(url, quote=True)

    lines = [f"üß† <b>{safe_title}</b>"]

    # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
    if body:
        safe_body = escape(body)
        lines.append("")
        lines.append(safe_body)

    lines.append("")
    lines.append(f'üîó <a href="{safe_url}">–ò—Å—Ç–æ—á–Ω–∏–∫</a>')

    return "\n".join(lines)


# ==========================
#      JOB: –ù–û–í–û–°–¢–ò
# ==========================


async def periodic_news(context: ContextTypes.DEFAULT_TYPE):
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ –≤ –∫–∞–Ω–∞–ª."""
    logger.info("–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏‚Ä¶")

    try:
        news = fetch_news()

        if not news:
            logger.info("–°–≤–µ–∂–∏—Ö –ò–ò-–Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç.")
            return

        count = 0
        for item in news:
            if count >= MAX_POSTS_PER_RUN:
                logger.info("–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç %d –ø–æ—Å—Ç–æ–≤ –∑–∞ —Ü–∏–∫–ª.", MAX_POSTS_PER_RUN)
                break

            url = item["url"]
            if url in sent_urls:
                continue

            post = build_post_text(item)

            try:
                await context.bot.send_message(
                    chat_id=CHANNEL_ID,
                    text=post,
                    parse_mode=ParseMode.HTML,
                    disable_web_page_preview=False,
                )
                logger.info("–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å: %s", url)

                sent_urls.add(url)
                save_sent_urls()
                count += 1

            except Exception as e:
                logger.exception("–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ—Å—Ç–∞: %s", e)
                await notify_admin(context, f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ—Å—Ç–∞: {e}")

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ periodic_news: %s", e)
        await notify_admin(context, f"–û—à–∏–±–∫–∞ periodic_news: {e}")


# ==========================
#         HANDLERS
# ==========================


async def start_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç!\n"
        "–≠—Ç–æ –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –±–æ—Ç –æ–± –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ.\n"
        "–û–Ω —Å–æ–±–∏—Ä–∞–µ—Ç –ò–ò-–Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ —Ä—É—Å—Å–∫–∏—Ö –∏ –∑–∞—Ä—É–±–µ–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤,\n"
        "–ø–µ—Ä–µ–≤–æ–¥–∏—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π –∏ –ø—É–±–ª–∏–∫—É–µ—Ç –¥–æ 5 –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —Ü–∏–∫–ª –±–µ–∑ —Å–ø–∞–º–∞."
    )


# ==========================
#          MAIN
# ==========================


def main():
    logger.info("–ó–∞–ø—É—Å–∫ ai-news-worker‚Ä¶")
    load_sent_urls()

    app = Application.builder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start_handler))

    app.job_queue.run_repeating(
        periodic_news,
        interval=NEWS_INTERVAL,
        first=10,
        name="periodic_news",
    )

    app.run_polling()


if __name__ == "__main__":
    main()
